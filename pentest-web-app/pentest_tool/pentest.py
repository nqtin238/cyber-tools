import os
import requests
import nmap
import jwt
import json
import itertools
import pandas as pd
import logging
import tldextract
import dns.resolver
from bs4 import BeautifulSoup
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
import time
import subprocess
from datetime import datetime, timedelta
from jinja2 import Environment, FileSystemLoader
import tenacity
from stem import Signal
from stem.control import Controller
import argparse
import docker
import pkg_resources
import configparser
from dotenv import load_dotenv

# Configure Logging
logging.basicConfig(filename="/home/parrot/pentest.log", level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Load .env file with fallback handling
load_dotenv()
NVD_API_KEY = os.getenv("NVD_API_KEY", "N/A")
VALID_USERNAME = os.getenv("VALID_USERNAME", "N/A")
VALID_PASSWORD = os.getenv("VALID_PASSWORD", "N/A")
ENV = os.getenv("ENV", "production")
CACHE_TTL_DAYS = int(os.getenv("CACHE_TTL_DAYS", "1"))

# Load and validate .config file
config = configparser.ConfigParser()
config_file = ".config"
if not os.path.exists(config_file):
    logging.warning(f"Configuration file '{config_file}' not found. Using defaults where possible.")
else:
    config.read(config_file)

# Default values if sections/keys are missing
TARGETS = config.get("Targets", {}).get("api", "http://localhost:5000")
FRONTEND_URL = config.get("Targets", {}).get("frontend", "http://localhost:3000")
TARGET_IP = config.get("Targets", {}).get("ip", "127.0.0.1")
DEPENDENCY_VERSIONS = dict(config.items("DependencyVersions", fallback={"flask": "0.0.0", "postgresql": "0.0.0", "nginx": "0.0.0", "docker": "0.0.0"}))
ENDPOINTS = config.get("Endpoints", "endpoints", fallback="/invoices,/admin,/login").split(",")
SUBDOMAINS = config.get("Subdomains", "subdomains", fallback="www,api,staging").split(",")
DICTIONARIES = dict(config.items("Dictionaries", fallback={
    "usernames_file": "/home/parrot/pentest_tool/wordlists/usernames.txt",
    "passwords_file": "/home/parrot/pentest_tool/wordlists/passwords.txt",
    "sql_payloads_file": "/home/parrot/pentest_tool/wordlists/sql_payloads.txt",
    "xss_payloads_file": "/home/parrot/pentest_tool/wordlists/xss_payloads.txt",
    "fuzz_paths_file": "/home/parrot/pentest_tool/wordlists/fuzz_paths.txt"
}))

# Load dictionaries with error handling
def load_dictionary(file_path):
    try:
        with open(file_path, "r") as f:
            return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        logging.warning(f"Dictionary file not found: {file_path}. Skipping related tests.")
        return []
    except PermissionError:
        logging.warning(f"Permission denied for dictionary file: {file_path}. Skipping related tests.")
        return []
    except Exception as e:
        logging.error(f"Failed to load dictionary {file_path}: {e}. Skipping related tests.")
        return []

USERNAME_LIST = load_dictionary(DICTIONARIES.get("usernames_file", ""))
PASSWORD_LIST = load_dictionary(DICTIONARIES.get("passwords_file", ""))
SQL_PAYLOADS = load_dictionary(DICTIONARIES.get("sql_payloads_file", ""))
XSS_PAYLOADS = load_dictionary(DICTIONARIES.get("xss_payloads_file", ""))
FUZZ_PATHS = load_dictionary(DICTIONARIES.get("fuzz_paths_file", ""))

# Dynamic Dependency Detection with fallback
try:
    DEPENDENCY_VERSIONS["flask"] = pkg_resources.get_distribution("flask").version
except Exception:
    logging.warning("Failed to detect Flask version. Using config value.")
try:
    DEPENDENCY_VERSIONS["postgresql"] = subprocess.check_output(["psql", "--version"]).decode().split()[2]
except Exception:
    logging.warning("Failed to detect PostgreSQL version. Using config value.")
try:
    DEPENDENCY_VERSIONS["nginx"] = subprocess.check_output(["nginx", "-v"]).decode().split("/")[1].strip()
except Exception:
    logging.warning("Failed to detect Nginx version. Using config value.")
try:
    DEPENDENCY_VERSIONS["docker"] = subprocess.check_output(["docker", "--version"]).decode().split()[2].strip(",")
except Exception:
    logging.warning("Failed to detect Docker version. Using config value.")

# Validate environment
if ENV != "staging":
    logging.warning("Running on non-staging environment (ENV != staging). Proceeding with caution.")
    # Optionally exit or continue based on policy
    # exit(1)  # Uncomment to enforce staging only

VALID_CREDENTIALS = {"username": VALID_USERNAME, "password": VALID_PASSWORD} if VALID_USERNAME != "N/A" and VALID_PASSWORD != "N/A" else {}

HEADERS = {"Content-Type": "application/json"}
SESSION = requests.Session()
RETRY_STRATEGY = tenacity.retry(stop=tenacity.stop_after_attempt(3), wait=tenacity.wait_fixed(2))

# Ensure report directory exists
REPORT_DIR = "/home/parrot/pentest_reports"
os.makedirs(REPORT_DIR, exist_ok=True)
REPORT_FILE = f"{REPORT_DIR}/pentest_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
HTML_TEMPLATE = "report_template.html"
HTML_OUTPUT = f"{REPORT_DIR}/pentest_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
PDF_OUTPUT = f"{REPORT_DIR}/pentest_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"

# HTML template environment
env = Environment(loader=FileSystemLoader("."), trim_blocks=True)

# --- Utility Functions ---

def get_jwt_token():
    if not VALID_CREDENTIALS:
        logging.warning("No valid credentials available. Skipping authenticated tests.")
        return None
    try:
        response = SESSION.post(TARGETS + "/login", json=VALID_CREDENTIALS)
        response.raise_for_status()
        return response.json().get("access_token")
    except requests.RequestException as e:
        logging.error(f"Failed to get JWT token: {e}. Skipping authenticated tests.")
        return None

def run_command(command):
    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        return result.stdout, result.stderr, 0
    except subprocess.CalledProcessError as e:
        logging.error(f"Command failed: {e}")
        return "", str(e), e.returncode

def get_tor_session():
    session = requests.Session()
    session.proxies = {"http": "socks5h://localhost:9050", "https": "socks5h://localhost:9050"}
    try:
        with Controller.from_port(port=9051) as controller:
            controller.authenticate()
            controller.signal(Signal.NEWNYM)
    except Exception as e:
        logging.error(f"Tor connection failed: {e}")
    return session

# --- NVD Integration ---

def fetch_nvd_cves(api_key=None, force_refresh=False):
    cache_file = "cve_cache.json"
    if not force_refresh and os.path.exists(cache_file):
        try:
            with open(cache_file, "r") as f:
                cached_data = json.load(f)
            if (datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))).days < CACHE_TTL_DAYS:
                return cached_data
        except json.JSONDecodeError:
            logging.warning("Cache file corrupted, refreshing data")
            os.remove(cache_file)

    url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
    params = {
        "startIndex": 0,
        "resultsPerPage": 2000,
        "keywordSearch": "flask postgresql nginx docker",
        "pubStartDate": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%dT00:00:00:000 UTC-08:00")
    }
    headers = {"apiKey": api_key} if api_key and api_key != "N/A" else {}
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        data = response.json()
        cves = [
            {
                "id": cve["cve"]["id"],
                "description": cve["cve"]["descriptions"][0]["value"],
                "cvss_v3": cve["metrics"].get("cvssMetricV31", [{}])[0].get("cvssData", {}).get("baseScore", "N/A"),
                "affected": [
                    {
                        "cpe": c["cpe22Uri"],
                        "versionStartIncluding": c.get("versionStartIncluding", ""),
                        "versionEndIncluding": c.get("versionEndIncluding", "")
                    }
                    for c in cve.get("configurations", {}).get("nodes", [])[0].get("cpeMatch", [])
                ]
            }
            for cve in data.get("vulnerabilities", [])
            if any(tech in cve["cve"]["id"].lower() or tech in cve["cve"]["descriptions"][0]["value"].lower()
                   for tech in ["flask", "postgresql", "nginx", "docker"])
        ]
        with open(cache_file, "w") as f:
            json.dump(cves, f)
        return cves
    except requests.RequestException as e:
        logging.error(f"Failed to fetch NVD CVEs: {e}. Using cached data if available.")
        return [] if not os.path.exists(cache_file) else json.load(open(cache_file, "r"))

def match_cve_versions(cve_data, dependency_versions):
    relevant_cves = []
    for cve in cve_data:
        for affected in cve["affected"]:
            cpe_parts = affected["cpe"].split(":")
            if len(cpe_parts) >= 5:
                product = cpe_parts[3]
                version = cpe_parts[4]
                if product in dependency_versions:
                    expected_version = dependency_versions[product]
                    version_start = affected.get("versionStartIncluding", "")
                    version_end = affected.get("versionEndIncluding", "")
                    if (not version_start or expected_version >= version_start) and (not version_end or expected_version <= version_end):
                        relevant_cves.append(cve)
                        break
    return relevant_cves

# --- Test Functions with Error Handling ---

def scan_ports():
    try:
        nm = nmap.PortScanner()
        nm.scan(TARGET_IP, '1-65535')
        open_ports = [port for port in nm[TARGET_IP].get('tcp', {}) if nm[TARGET_IP]['tcp'][port]['state'] == 'open']
        return open_ports if open_ports else ["No open ports found"]
    except Exception as e:
        logging.warning(f"Port scan failed: {e}. Skipping test.")
        return ["Port scan skipped due to error"]

def check_exposed_endpoints(cve_data):
    if not get_jwt_token():
        logging.warning("No JWT token available. Skipping exposed endpoints test.")
        return ["Exposed endpoints test skipped due to authentication failure"]
    endpoints = ENDPOINTS
    relevant_cves = match_cve_versions(cve_data, DEPENDENCY_VERSIONS)
    exposed = []
    for endpoint in set(endpoints):
        try:
            response = SESSION.get(TARGETS + endpoint, headers={"Authorization": f"Bearer {get_jwt_token()}"})
            if response.status_code == 200:
                exposed.append(endpoint)
        except requests.RequestException as e:
            logging.warning(f"Endpoint {endpoint} inaccessible: {e}")
    return exposed if exposed else ["No exposed endpoints"]

def test_sql_injection(cve_data):
    if not SQL_PAYLOADS:
        logging.warning("No SQL payloads available. Skipping SQL injection test.")
        return ["SQL injection test skipped due to missing payloads"]
    tor_session = get_tor_session()
    payloads = SQL_PAYLOADS
    relevant_cves = match_cve_versions(cve_data, DEPENDENCY_VERSIONS)
    for cve in relevant_cves:
        if "postgresql" in cve["affected"][0]["cpe"].lower() and "sql injection" in cve["description"].lower():
            payloads.append("' " + cve["description"].split("injection")[0].split()[-1] + " --")
    for payload in set(payloads):
        try:
            response = tor_session.get(TARGETS + "/login?user=" + payload)
            if "error" not in response.text.lower() and "invalid" not in response.text.lower():
                return f"SQL Injection Vulnerable with payload: {payload} (CVE-related, Tor)"
        except requests.RequestException as e:
            logging.error(f"SQL injection test failed: {e}")
    return "Safe"

def test_xss(cve_data):
    if not XSS_PAYLOADS:
        logging.warning("No XSS payloads available. Skipping XSS test.")
        return ["XSS test skipped due to missing payloads"]
    payloads = XSS_PAYLOADS
    relevant_cves = match_cve_versions(cve_data, DEPENDENCY_VERSIONS)
    for cve in relevant_cves:
        if "flask" in cve["affected"][0]["cpe"].lower() and "xss" in cve["description"].lower():
            payloads.append("<script>" + cve["description"].split("xss")[0].split()[-1] + "</script>")
    for payload in set(payloads):
        try:
            response = SESSION.post(TARGETS + "/search", data={"query": payload}, headers={"Authorization": f"Bearer {get_jwt_token()}"})
            if any(p in response.text for p in payloads):
                return f"XSS Detected with payload: {payload} (CVE-related)"
        except requests.RequestException as e:
            logging.error(f"XSS test failed: {e}")
    return "Safe"

def brute_force_login():
    if not USERNAME_LIST or not PASSWORD_LIST:
        logging.warning("No usernames or passwords available. Skipping brute-force test.")
        return ["Brute-force test skipped due to missing dictionaries"]
    max_attempts = 10
    for i, (username, password) in enumerate(itertools.product(USERNAME_LIST, PASSWORD_LIST)):
        if i >= max_attempts:
            break
        data = {"username": username, "password": password}
        try:
            response = SESSION.post(TARGETS + "/login", json=data)
            if response.status_code == 200 and "invalid" not in response.text.lower():
                return f"Login Successful with {username}:{password}"
            time.sleep(1)
        except requests.RequestException as e:
            logging.error(f"Brute-force attempt failed: {e}")
    return "Brute-force Failed (No valid credentials or rate-limited)"

def validate_jwt():
    token = get_jwt_token()
    if token is None:
        logging.warning("No JWT token available. Skipping JWT validation.")
        return ["JWT validation skipped due to authentication failure"]
    try:
        decoded = jwt.decode(token, options={"verify_signature": False})
        header = jwt.get_unverified_header(token)
        if header.get("alg") in ["none", "HS256"]:
            return f"WARNING: Weak JWT Algorithm ({header['alg']}) detected!"
        return f"JWT Valid: {json.dumps(decoded, indent=2)}"
    except jwt.ExpiredSignatureError:
        return "JWT Expired"
    except jwt.InvalidTokenError as e:
        return f"Invalid JWT Token: {e}"

def fuzz_endpoints(cve_data):
    if not FUZZ_PATHS:
        logging.warning("No fuzz paths available. Skipping endpoint fuzzing.")
        return ["Endpoint fuzzing skipped due to missing paths"]
    common_paths = FUZZ_PATHS
    relevant_cves = match_cve_versions(cve_data, DEPENDENCY_VERSIONS)
    found_paths = []
    for path in set(common_paths):
        try:
            response = SESSION.get(TARGETS + "/" + path, headers={"Authorization": f"Bearer {get_jwt_token()}"})
            if response.status_code == 200:
                found_paths.append(path)
        except requests.RequestException as e:
            logging.warning(f"Fuzzing {path} failed: {e}")
    return found_paths if found_paths else ["No additional endpoints found"]

def detect_https_stripping():
    parsed_url = urlparse(TARGETS)
    http_url = f"http://{parsed_url.netloc}{parsed_url.path}"
    try:
        response = SESSION.get(http_url, allow_redirects=False)
        return "WARNING: HTTPS Stripping detected!" if response.status_code == 200 else "Secure"
    except requests.ConnectionError:
        logging.warning(f"HTTPS stripping test failed due to connection error.")
        return ["HTTPS stripping test skipped"]

def enumerate_subdomains():
    if not SUBDOMAINS:
        logging.warning("No subdomains available. Skipping subdomain enumeration.")
        return ["Subdomain enumeration skipped due to missing subdomains"]
    domain = tldextract.extract(TARGETS).registered_domain
    subdomains = []
    for sub in SUBDOMAINS:
        try:
            answers = dns.resolver.resolve(f"{sub}.{domain}", "A")
            subdomains.append(f"{sub}.{domain}")
        except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
            continue
        except Exception as e:
            logging.error(f"Subdomain check {sub} failed: {e}")
    return subdomains if subdomains else ["No subdomains found"]

def analyze_api_responses():
    training_responses = ["Success: User logged in", "Error 404: Not Found", "Success: Invoice created"]
    test_responses = ["System failure detected", "Error 500: Internal Server Error"]
    vectorizer = TfidfVectorizer()
    X_train = vectorizer.fit_transform(training_responses)
    model = NearestNeighbors(n_neighbors=1).fit(X_train)
    anomalies = []
    for test_response in test_responses:
        test_vector = vectorizer.transform([test_response])
        _, indices = model.kneighbors(test_vector)
        if indices[0][0] >= len(training_responses) - 1:
            anomalies.append(test_response)
    return f"Potential Anomalies: {anomalies}" if anomalies else "No anomalies detected"

def test_csrf():
    if not get_jwt_token():
        logging.warning("No JWT token available. Skipping CSRF test.")
        return ["CSRF test skipped due to authentication failure"]
    try:
        response = SESSION.get(TARGETS + "/invoices", headers={"Authorization": f"Bearer {get_jwt_token()}"})
        if "csrf-token" not in response.cookies and "csrf-token" not in response.headers:
            return "WARNING: CSRF token not found!"
        return "CSRF Protection Detected"
    except requests.RequestException as e:
        logging.error(f"CSRF test failed: {e}")
        return ["CSRF test skipped due to error"]

def check_directory_listing():
    dirs = ["/static", "/uploads", "/backup"]
    exposed = []
    for directory in dirs:
        try:
            response = SESSION.get(TARGETS + directory)
            if response.status_code == 200 and "index of" in response.text.lower():
                exposed.append(directory)
        except requests.RequestException as e:
            logging.warning(f"Directory {directory} check failed: {e}")
    return exposed if exposed else ["No directory listing"]

def check_debug_mode():
    try:
        response = SESSION.get(TARGETS + "/nonexistent")
        return "WARNING: Debug mode enabled!" if "DEBUG" in response.text.upper() and "Traceback" in response.text else "Debug mode disabled"
    except requests.RequestException as e:
        logging.warning(f"Debug mode test failed: {e}. Skipping test.")
        return ["Debug mode test skipped"]

def check_db_exposure():
    try:
        nm = nmap.PortScanner()
        nm.scan(TARGET_IP, '5432')
        return "WARNING: PostgreSQL port exposed!" if "5432/tcp" in nm[TARGET_IP].get('tcp', {}) and nm[TARGET_IP]['tcp']['5432']['state'] == 'open' else "PostgreSQL port secure"
    except Exception as e:
        logging.warning(f"DB exposure check failed: {e}. Skipping test.")
        return ["DB exposure check skipped"]

def check_nginx_security():
    try:
        response = SESSION.get(FRONTEND_URL)
        headers = response.headers
        issues = []
        if "Strict-Transport-Security" not in headers:
            issues.append("HSTS header missing")
        if response.url.startswith("http://"):
            issues.append("HTTP to HTTPS redirect not enforced")
        return issues if issues else ["Nginx configuration secure"]
    except requests.RequestException as e:
        logging.warning(f"Nginx security check failed: {e}. Skipping test.")
        return ["Nginx security check skipped"]

def test_ssti():
    payload = "{{7*7}}"
    try:
        response = SESSION.get(TARGETS + "/render?input=" + payload)
        return "SSTI Vulnerable (result: 49)" if "49" in response.text else "Safe"
    except requests.RequestException:
        logging.warning("SSTI test failed due to connection error. Skipping test.")
        return ["SSTI test skipped"]

def check_docker_security():
    try:
        client = docker.from_client()
        containers = client.containers.list()
        issues = []
        for container in containers:
            if "0.0.0.0" in str(container.ports):
                issues.append(f"Container {container.name} exposes ports to 0.0.0.0")
        return issues if issues else ["No Docker security issues"]
    except Exception as e:
        logging.warning(f"Docker security check failed: {e}. Skipping test.")
        return ["Docker security check skipped"]

def check_sensitive_data():
    if not get_jwt_token():
        logging.warning("No JWT token available. Skipping sensitive data check.")
        return ["Sensitive data check skipped due to authentication failure"]
    try:
        response = SESSION.get(TARGETS + "/invoices", headers={"Authorization": f"Bearer {get_jwt_token()}"})
        if any(keyword in response.text.lower() for keyword in ["password", "credit_card", "ssn"]):
            return "WARNING: Sensitive data exposed!"
        return "No sensitive data detected"
    except requests.RequestException as e:
        logging.error(f"Sensitive data check failed: {e}")
        return ["Sensitive data check skipped due to error"]

# --- ParrotOS Tool Integrations ---

def enhance_sql_injection():
    if not SQL_PAYLOADS:
        logging.warning("No SQL payloads available. Skipping enhanced SQL injection test.")
        return ["Enhanced SQL injection test skipped due to missing payloads"]
    try:
        result = subprocess.run(
            ["sqlmap", "-u", f"{TARGETS}/login", "--batch", "--level=3", "--risk=2", "--dbms=postgresql"],
            capture_output=True, text=True, timeout=300
        )
        return "SQLMap Results: " + result.stdout if result.returncode == 0 else f"SQLMap Failed: {result.stderr}"
    except subprocess.TimeoutExpired as e:
        logging.error(f"SQLMap timed out: {e}")
        return "SQLMap Timed Out"
    except Exception as e:
        logging.error(f"SQLMap integration failed: {e}")
        return "SQLMap Error"

def enhance_network_scan():
    try:
        result = subprocess.run(
            ["nikto", "-h", TARGETS, "-output", f"{REPORT_DIR}/nikto_scan.txt"],
            capture_output=True, text=True, timeout=300
        )
        with open(f"{REPORT_DIR}/nikto_scan.txt", "r") as f:
            return "Nikto Scan: " + f.read() if result.returncode == 0 else f"Nikto Failed: {result.stderr}"
    except subprocess.TimeoutExpired as e:
        logging.error(f"Nikto timed out: {e}")
        return "Nikto Timed Out"
    except Exception as e:
        logging.error(f"Nikto integration failed: {e}")
        return "Nikto Error"

def add_forensic_report():
    try:
        result = subprocess.run(
            ["autopsy", "-d", "/tmp/forensic"],
            capture_output=True, text=True, timeout=300
        )
        return "Forensic Report: " + result.stdout if result.returncode == 0 else "Forensic Failed"
    except subprocess.TimeoutExpired as e:
        logging.error(f"Forensic timed out: {e}")
        return "Forensic Timed Out"
    except Exception as e:
        logging.error(f"Forensic integration failed: {e}")
        return "Forensic Error"

# --- Reporting ---

def generate_report(results, cve_data):
    relevant_cves = match_cve_versions(cve_data, DEPENDENCY_VERSIONS)
    summary = {"high": 0, "medium": 0, "low": 0}
    for result in results.values():
        severity = "High" if "Vulnerable" in str(result) or "WARNING" in str(result) else "Medium" if "No" in str(result) or "skipped" in str(result).lower() else "Low"
        summary[severity.lower()] += 1

    with open(REPORT_FILE, "w", newline="") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=["Test", "Result", "Timestamp", "Severity", "CVE Reference", "Suggestion"])
        writer.writeheader()
        for test, result in results.items():
            severity = "High" if "Vulnerable" in str(result) or "WARNING" in str(result) else "Medium" if "No" in str(result) or "skipped" in str(result).lower() else "Low"
            cve_ref = ", ".join([cve["id"] for cve in relevant_cves if test.lower() in cve["description"].lower()]) or "N/A"
            suggestion = "Patch immediately" if severity == "High" else "Review configuration" if severity == "Medium" else "No action needed"
            writer.writerow({
                "Test": test,
                "Result": str(result),
                "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "Severity": severity,
                "CVE Reference": cve_ref,
                "Suggestion": suggestion
            })
            logging.info(f"{test}: {result} (Severity: {severity}, CVE: {cve_ref})")

    template = env.get_template(HTML_TEMPLATE)
    html_content = template.render(results=results, cve_data=relevant_cves, timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"), summary=summary)
    with open(HTML_OUTPUT, "w") as htmlfile:
        htmlfile.write(html_content)

    pdf = canvas.Canvas(PDF_OUTPUT, pagesize=letter)
    y = 750
    pdf.drawString(100, y, f"Pentest Report - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    y -= 20
    for test, result in results.items():
        pdf.drawString(100, y, f"{test}: {result}")
        y -= 15
        if y < 50:
            pdf.showPage()
            y = 750
    pdf.save()

# --- CLI Interface ---

def parse_args():
    parser = argparse.ArgumentParser(description="Pentest Tool for Web Applications")
    parser.add_argument("--target", help="Target URL", default=TARGETS)
    parser.add_argument("--tests", nargs="+", help="Tests to run", default=["all"])
    parser.add_argument("--output", choices=["csv", "html", "pdf"], default="html")
    parser.add_argument("--force-refresh", action="store_true", help="Force refresh CVE cache")
    return parser.parse_args()

# --- Main Execution ---

if __name__ == "__main__":
    args = parse_args()
    cve_data = fetch_nvd_cves(NVD_API_KEY, args.force_refresh)

    tests_to_run = {
        "Open Ports": scan_ports,
        "Exposed Endpoints": lambda: check_exposed_endpoints(cve_data),
        "SQL Injection": lambda: test_sql_injection(cve_data),
        "XSS Vulnerability": lambda: test_xss(cve_data),
        "Brute-force Attack": brute_force_login,
        "JWT Validation": validate_jwt,
        "Fuzzed Endpoints": lambda: fuzz_endpoints(cve_data),
        "HTTPS Stripping": detect_https_stripping,
        "Subdomain Enumeration": enumerate_subdomains,
        "AI Threat Detection": analyze_api_responses,
        "CSRF Protection": test_csrf,
        "Directory Listing": check_directory_listing,
        "Flask Debug Mode": check_debug_mode,
        "PostgreSQL Exposure": check_db_exposure,
        "Nginx Security": check_nginx_security,
        "SSTI Vulnerability": test_ssti,
        "Docker Security": check_docker_security,
        "Sensitive Data Exposure": check_sensitive_data,
        "Enhanced SQL Injection (sqlmap)": enhance_sql_injection,
        "Enhanced Network Scan (nikto)": enhance_network_scan,
        "Forensic Report": add_forensic_report
    }

    if "all" in args.tests:
        selected_tests = tests_to_run
    else:
        selected_tests = {name: func for name, func in tests_to_run.items() if name.lower() in [t.lower() for t in args.tests]}

    with ThreadPoolExecutor(max_workers=3) as executor:
        future_to_test = {executor.submit(func): name for name, func in selected_tests.items()}
        results = {future_to_test[future]: future.result() for future in as_completed(future_to_test)}

    generate_report(results, cve_data)
    print("Pentest Completed! Reports saved to:", REPORT_DIR)